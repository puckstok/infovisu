Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/jupyter_cache/executors/utils.py", line 58, in single_nb_execution
    executenb(
  File "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/nbclient/client.py", line 1265, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/jupyter_core/utils/__init__.py", line 166, in wrapped
    return loop.run_until_complete(inner)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py", line 650, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py", line 222, in __aexit__
    await self.gen.athrow(typ, value, traceback)
  File "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/nbclient/client.py", line 648, in async_setup_kernel
    yield
  File "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/nbclient/client.py", line 703, in async_execute
    await self.async_execute_cell(
  File "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/nbclient/client.py", line 1021, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/nbclient/client.py", line 915, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
#voorbeeld laten zien in werkgroep 

#Stap 1: Laad en filter de relevante datasets
data_raw = pd.read_csv('migranten_eu.csv')
data_ter = pd.read_csv('terrorism_eu.csv').rename(columns={'country_txt': 'Country of asylum', 'iyear': 'Year', 'multiple': 'Terrorist attacks'})
data_lon_lat = pd.read_csv('world_country_and_usa_states_latitude_and_longitude_values.csv').rename(columns={'country': 'Country of asylum'})

df_ter = pd.read_csv('globalterrorismdb_0718dist.csv', encoding='latin-1')
df_ter.head()
df1_ter = df_ter.groupby(['iyear', 'region_txt', 'country_txt', 'gname']).count().reset_index()
df1_ter
mask = df1_ter[df1_ter['region_txt'].isin(['Eastern Europe', 'Western Europe'])]
mask
df2_ter = mask[mask.iyear.between(2000, 2017)]
df2_ter
df3_ter = df2_ter.groupby(['iyear']).count().reset_index()
df3_ter = df2_ter.groupby('iyear')['eventid'].sum().reset_index().rename(columns = {'iyear' : 'year', 'eventid' : 'count'})
df4_ter = df2_ter.groupby('country_txt')['eventid'].sum().reset_index().rename(columns = {'country_txt' : 'country', 'eventid' : 'count'})
df4_ter
df3_ter

df5_ter = df2_ter[['iyear', 'country_txt', 'eventid', 'gname']].rename(columns = {'iyear' : 'year', 'country_txt' : 'country', 'eventid' : 'count', 'gname' : 'group'})
df5_ter

data_raw.drop(data_raw.loc[data_raw['Year']==1999].index, inplace=True)
data_raw.head(5) 

#Stap 2: Versimpel langere namen van landen om later toe te passen in de samenvoeging van datasets 
migranten_totaal_europa = data_raw[['Year', 'Country of asylum', "Refugees under UNHCR's mandate"]]
migranten_totaal_europa['Country of asylum'] = migranten_totaal_europa['Country of asylum'].replace({'Netherlands (Kingdom of the)': 'Netherlands'})
migranten_totaal_europa['Country of asylum'] = migranten_totaal_europa['Country of asylum'].replace({'United Kingdom of Great Britain and Northern Ireland': 'United Kingdom'})
migranten_totaal_europa['Country of asylum'] = migranten_totaal_europa['Country of asylum'].replace({'Serbia and Kosovo: S/RES/1244 (1999)': 'Serbia'})
migranten_totaal_europa.head(5) 

populatie_eu = df1_ter = migranten_totaal_europa.groupby(['Year']).sum()

data_ter['Country of asylum'] = data_ter['Country of asylum'].replace({'Macedonia': 'North Macedonia'})
data_ter['Country of asylum'] = data_ter['Country of asylum'].replace({'Slovak Republic': 'Slovakia'})
data_ter['Country of asylum'] = data_ter['Country of asylum'].replace({'Serbia-Montenegro': 'Serbia'})
data_ter = data_ter[['Country of asylum', 'Year', 'Terrorist attacks']]
data_ter.head(5)

data_lon_lat['Country of asylum'] = data_lon_lat['Country of asylum'].replace({'Macedonia [FYROM]': 'North Macedonia'})
data_lon_lat2 = data_lon_lat[['latitude', 'longitude', 'Country of asylum']]
data_lon_lat2.head(5)

#Stap 3: Maak een nieuwe dataframe 
df2 = migranten_totaal_europa.groupby(['Year','Country of asylum'], as_index=False)["Refugees under UNHCR's mandate"].sum()
print(df2)

df3 = migranten_totaal_europa.groupby(['Year'], as_index=False)["Refugees under UNHCR's mandate"].sum()
print(df3)

df4 = migranten_totaal_europa.groupby(['Country of asylum'], as_index=False)["Refugees under UNHCR's mandate"].sum()
print(df4)

df3_ter
sum(df3_ter['count'])

#Stap 4: voeg de data van terroristische aanslagen en aantal vluchtelingen samen 
df_half = df2.merge(data_lon_lat2, on='Country of asylum')
df_full = pd.merge(df_half, data_ter,  how='left', left_on=['Country of asylum','Year'], right_on = ['Country of asylum','Year']).fillna(0)
df_full.head(500) 
#df_full.to_csv('test.csv')

#Stap 5: maak map figuur 
fig = px.scatter_geo(df_full, 
                     lat='latitude',
                     lon='longitude',
                     color="Refugees under UNHCR's mandate",
                     color_continuous_scale=px.colors.sequential.OrRd,
                     height=650,
                     width=950,
                     hover_name="Country of asylum",
                     hover_data={
                                "Refugees under UNHCR's mandate":True, 
                                "Terrorist attacks":True,
                                "latitude":False, 
                                "longitude":False,
                                },
                     projection="natural earth",
                     scope="europe",
                     size=df_full["Year"],
                     size_max=10,
                     animation_frame="Year",
                     range_color=(0,200000),
                    )


fig.update_geos(
    visible=True, 
    resolution=50,
    showcountries=True, 
    countrycolor="whitesmoke",
    bgcolor='whitesmoke',
    landcolor='#26a783',
)

fig.update_layout(
    title='Hoeveelheid vluchtelingen en terroristische aanvallen tussen 2000 en 2017',
)

fig.update_traces(marker=dict(line=dict(width=0.5, color='black')))
fig.show()

#Stap 6: maak de nieuwe files voor de datastory 
# df2.to_csv('migranten_per_jaar_per_land.csv')
# df3.to_csv('migranten_per_jaar_europa.csv')
# df4.to_csv('migranten_per_land_totaal.csv')
# populatie_eu.to_csv('populatie_eu.csv')
# df3_ter.to_csv('aanslagen_per_jaar.csv', index=False, header=True)
# df4_ter.to_csv('totale_aanslagen_per_land.csv', index=False, header=True)
# df5_ter.to_csv('aanslagen_per_jaar_per_land_per_groep.csv', index=False, header=True)
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mParserError[0m                               Traceback (most recent call last)
Cell [0;32mIn[2], line 8[0m
[1;32m      5[0m data_ter [38;5;241m=[39m pd[38;5;241m.[39mread_csv([38;5;124m'[39m[38;5;124mterrorism_eu.csv[39m[38;5;124m'[39m)[38;5;241m.[39mrename(columns[38;5;241m=[39m{[38;5;124m'[39m[38;5;124mcountry_txt[39m[38;5;124m'[39m: [38;5;124m'[39m[38;5;124mCountry of asylum[39m[38;5;124m'[39m, [38;5;124m'[39m[38;5;124miyear[39m[38;5;124m'[39m: [38;5;124m'[39m[38;5;124mYear[39m[38;5;124m'[39m, [38;5;124m'[39m[38;5;124mmultiple[39m[38;5;124m'[39m: [38;5;124m'[39m[38;5;124mTerrorist attacks[39m[38;5;124m'[39m})
[1;32m      6[0m data_lon_lat [38;5;241m=[39m pd[38;5;241m.[39mread_csv([38;5;124m'[39m[38;5;124mworld_country_and_usa_states_latitude_and_longitude_values.csv[39m[38;5;124m'[39m)[38;5;241m.[39mrename(columns[38;5;241m=[39m{[38;5;124m'[39m[38;5;124mcountry[39m[38;5;124m'[39m: [38;5;124m'[39m[38;5;124mCountry of asylum[39m[38;5;124m'[39m})
[0;32m----> 8[0m df_ter [38;5;241m=[39m [43mpd[49m[38;5;241;43m.[39;49m[43mread_csv[49m[43m([49m[38;5;124;43m'[39;49m[38;5;124;43mglobalterrorismdb_0718dist.csv[39;49m[38;5;124;43m'[39;49m[43m,[49m[43m [49m[43mencoding[49m[38;5;241;43m=[39;49m[38;5;124;43m'[39;49m[38;5;124;43mlatin-1[39;49m[38;5;124;43m'[39;49m[43m)[49m
[1;32m      9[0m df_ter[38;5;241m.[39mhead()
[1;32m     10[0m df1_ter [38;5;241m=[39m df_ter[38;5;241m.[39mgroupby([[38;5;124m'[39m[38;5;124miyear[39m[38;5;124m'[39m, [38;5;124m'[39m[38;5;124mregion_txt[39m[38;5;124m'[39m, [38;5;124m'[39m[38;5;124mcountry_txt[39m[38;5;124m'[39m, [38;5;124m'[39m[38;5;124mgname[39m[38;5;124m'[39m])[38;5;241m.[39mcount()[38;5;241m.[39mreset_index()

File [0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/util/_decorators.py:211[0m, in [0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper[0;34m(*args, **kwargs)[0m
[1;32m    209[0m     [38;5;28;01melse[39;00m:
[1;32m    210[0m         kwargs[new_arg_name] [38;5;241m=[39m new_arg_value
[0;32m--> 211[0m [38;5;28;01mreturn[39;00m [43mfunc[49m[43m([49m[38;5;241;43m*[39;49m[43margs[49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m

File [0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/util/_decorators.py:331[0m, in [0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper[0;34m(*args, **kwargs)[0m
[1;32m    325[0m [38;5;28;01mif[39;00m [38;5;28mlen[39m(args) [38;5;241m>[39m num_allow_args:
[1;32m    326[0m     warnings[38;5;241m.[39mwarn(
[1;32m    327[0m         msg[38;5;241m.[39mformat(arguments[38;5;241m=[39m_format_argument_list(allow_args)),
[1;32m    328[0m         [38;5;167;01mFutureWarning[39;00m,
[1;32m    329[0m         stacklevel[38;5;241m=[39mfind_stack_level(),
[1;32m    330[0m     )
[0;32m--> 331[0m [38;5;28;01mreturn[39;00m [43mfunc[49m[43m([49m[38;5;241;43m*[39;49m[43margs[49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m

File [0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:950[0m, in [0;36mread_csv[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)[0m
[1;32m    935[0m kwds_defaults [38;5;241m=[39m _refine_defaults_read(
[1;32m    936[0m     dialect,
[1;32m    937[0m     delimiter,
[0;32m   (...)[0m
[1;32m    946[0m     defaults[38;5;241m=[39m{[38;5;124m"[39m[38;5;124mdelimiter[39m[38;5;124m"[39m: [38;5;124m"[39m[38;5;124m,[39m[38;5;124m"[39m},
[1;32m    947[0m )
[1;32m    948[0m kwds[38;5;241m.[39mupdate(kwds_defaults)
[0;32m--> 950[0m [38;5;28;01mreturn[39;00m [43m_read[49m[43m([49m[43mfilepath_or_buffer[49m[43m,[49m[43m [49m[43mkwds[49m[43m)[49m

File [0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611[0m, in [0;36m_read[0;34m(filepath_or_buffer, kwds)[0m
[1;32m    608[0m     [38;5;28;01mreturn[39;00m parser
[1;32m    610[0m [38;5;28;01mwith[39;00m parser:
[0;32m--> 611[0m     [38;5;28;01mreturn[39;00m [43mparser[49m[38;5;241;43m.[39;49m[43mread[49m[43m([49m[43mnrows[49m[43m)[49m

File [0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1778[0m, in [0;36mTextFileReader.read[0;34m(self, nrows)[0m
[1;32m   1771[0m nrows [38;5;241m=[39m validate_integer([38;5;124m"[39m[38;5;124mnrows[39m[38;5;124m"[39m, nrows)
[1;32m   1772[0m [38;5;28;01mtry[39;00m:
[1;32m   1773[0m     [38;5;66;03m# error: "ParserBase" has no attribute "read"[39;00m
[1;32m   1774[0m     (
[1;32m   1775[0m         index,
[1;32m   1776[0m         columns,
[1;32m   1777[0m         col_dict,
[0;32m-> 1778[0m     ) [38;5;241m=[39m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43m_engine[49m[38;5;241;43m.[39;49m[43mread[49m[43m([49m[43m  [49m[38;5;66;43;03m# type: ignore[attr-defined][39;49;00m
[1;32m   1779[0m [43m        [49m[43mnrows[49m
[1;32m   1780[0m [43m    [49m[43m)[49m
[1;32m   1781[0m [38;5;28;01mexcept[39;00m [38;5;167;01mException[39;00m:
[1;32m   1782[0m     [38;5;28mself[39m[38;5;241m.[39mclose()

File [0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:230[0m, in [0;36mCParserWrapper.read[0;34m(self, nrows)[0m
[1;32m    228[0m [38;5;28;01mtry[39;00m:
[1;32m    229[0m     [38;5;28;01mif[39;00m [38;5;28mself[39m[38;5;241m.[39mlow_memory:
[0;32m--> 230[0m         chunks [38;5;241m=[39m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43m_reader[49m[38;5;241;43m.[39;49m[43mread_low_memory[49m[43m([49m[43mnrows[49m[43m)[49m
[1;32m    231[0m         [38;5;66;03m# destructive to chunks[39;00m
[1;32m    232[0m         data [38;5;241m=[39m _concatenate_chunks(chunks)

File [0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:808[0m, in [0;36mpandas._libs.parsers.TextReader.read_low_memory[0;34m()[0m

File [0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:866[0m, in [0;36mpandas._libs.parsers.TextReader._read_rows[0;34m()[0m

File [0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:852[0m, in [0;36mpandas._libs.parsers.TextReader._tokenize_rows[0;34m()[0m

File [0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:1973[0m, in [0;36mpandas._libs.parsers.raise_parser_error[0;34m()[0m

[0;31mParserError[0m: Error tokenizing data. C error: Expected 1 fields in line 26, saw 2

ParserError: Error tokenizing data. C error: Expected 1 fields in line 26, saw 2


